install.packages( "data.table", dependencies=TRUE )
rm( list=ls() )  #remove all objects
gc()
rm( list=ls() )  #remove all objects
gc()
require("data.table")
require(stringi)
require(stringr)
require(stringdist)
setwd("C:/Users/Asus/Desktop/CEP/Proveedores.Extranjeros")
{r setup}
knitr::opts_knit$set(root.dir = '~/Escritorio/CEP/Proveedores.Extranjeros/intrafirma')
install.packages("knitr")
knitr::opts_knit$set(root.dir = '~/Escritorio/CEP/Proveedores.Extranjeros/intrafirma')
install.packages("rmarkdown", dependencies = TRUE)
knitr::opts_knit$set(root.dir = '~/Escritorio/CEP/Proveedores.Extranjeros/intrafirma')
install.packages("knitr", dependencies=TRUE)
config.log
install.packages("knitr", dependencies=TRUE)
require("data.table")
knitr::opts_knit$set(root.dir = '/tmp')
knitr::opts_knit$set(root.dir = '/tmp')
install.packages("knitr", dependencies=TRUE)
knitr::opts_knit$set(root.dir = '/tmp')
getwd()
knitr::opts_knit$set(root.dir = '~/Escritorio/CEP/Proveedores.Extranjeros')
getwd()
rm( list=ls() )  #remove all objects
gc()
require("data.table")
require(stringi)
require(stringr)
require(stringdist)
data <- fread("./dataset_aduana/dataset_aduana_revision.csv", verbose = TRUE)
data <- fread("./dataset_aduana/dataset_aduana_revision.csv", verbose = TRUE)
knitr::opts_knit$set(root.dir = '~/Escritorio/CEP/Proveedores.Extranjeros')
rm( list=ls() )  #remove all objects
gc()
require("data.table")
require(stringi)
require(stringr)
require(stringdist)
data <- fread("./dataset_aduana/dataset_aduana_revision.csv", verbose = TRUE)
#Función de limpieza con Regex
CleaningRE <- function(txt){
txt = stri_trans_general(txt,"Latin-ASCII")
txt = toupper(txt)                 # todo a mayúscula
txt = gsub("\\([^()]*\\)", "",txt) # saca todo lo que está en paréntesis
txt = gsub('[[:punct:]]','',txt)   # punctuación
#txt = gsub('[[:digit:]]','',txt)  # tooodos los numeros
txt = gsub('\\b\\d+\\b','', txt)   # números sueltos
txt = gsub('\\s+',' ',txt)   # tooodos los espacios en blanco
return(txt)
}
#Función de ngramas a nivel de palabras
ngrams2 <- function(txt, k=3){
splitted <- unlist(str_split(txt,""))
shingles <- c()
for( i in 1:( length(splitted) - k + 1 ) ) {
shing_i <- paste( splitted[ i:(i + k - 1) ], collapse = "" )
shingles <- c(shingles, shing_i)
}
return(shingles)
}
#Similitud de Jaccard
jaccard_similarity <- function(a, b) {
intersection = length(intersect(a, b))
union = length(a) + length(b) - intersection
return (intersection/union)
}
#similitud de Jaccard aplicada a los shingles
jaccard_shingles <- function(x,y, n=3){
x <- ngrams2(x,k=n)
y <- ngrams2(y,k=n)
return(jaccard_similarity(x,y))
}
jaro_winkler <- function(x,y,p=0.1){
return(1-stringdist(x,y,method='jw', p=p))
}
clean_and_compute_similarity <- function(txt1,txt2, method='jaccard', n_shingles=3, jw_p=0.1, threshold=0.8){
txt1 <- CleaningRE(txt1)
txt2 <- CleaningRE(txt2)
if (method=="jaccard"){
s <- jaccard_shingles(txt1,txt2, n=n_shingles)
}
if (method=="jw"){
s <- jaro_winkler(txt1,txt2, p=jw_p)
}
if (method=="both"){
s1 <- jaccard_shingles(txt1,txt2, n=n_shingles)
s2 <- jaro_winkler(txt1,txt2, p=jw_p)
s <- (s1 + s2)/2
}
return(ifelse(s >threshold,1,0))
}
clean_and_return_similarity <- function(txt1,txt2, method='jaccard', n_shingles=3, jw_p=0.1){
txt1 <- CleaningRE(txt1)
txt2 <- CleaningRE(txt2)
if (method=="jaccard"){
return(jaccard_shingles(txt1,txt2, n=n_shingles))
}
if (method=="jw"){
return(jaro_winkler(txt1,txt2, p=jw_p))
}
if (method=="both"){
s1 <- jaccard_shingles(txt1,txt2, n=n_shingles)
s2 <- jaro_winkler(txt1,txt2, p=jw_p)
return((s1 + s2)/2)
}
}
data[, jaro_dist := clean_and_return_similarity(rsocial, NombreUltimaRevision, method="jw", jw_p=0)]
require('ggplot2')
ggplot(data=data, aes(x=jaro_dist))+geom_density()+ggtitle("Jaro Distance Distribution")
#agg <- data[anio!=2021,.(ValorCif = sum(cif)), keyby = .(rsocial,intrafirma)]
muestra <- data[sample(.N, 1137570)]
View(muestra)
ggplot(data=muestra, aes(x=jaro_dist))+geom_density()+ggtitle("Jaro Distance Distribution")
muestra[, jacc_dist := clean_and_return_similarity(rsocial, NombreUltimaRevision, method = "jaccard", n_shingles = 3)]
jaccard_shingles("ABRASIVOS MACKENZIE","ABRASIVOS SAINT GOBAIN", n=3)
stringdist("ABRASIVOS MACKENZIE","ABRASIVOS SAINT GOBAIN", method = "jaccard")
clean_and_return_similarity <- function(txt1,txt2, method='jaccard', qgram=3, jw_p=0.1){
txt1 <- CleaningRE(txt1)
txt2 <- CleaningRE(txt2)
if (method=="jaccard"){
return(jstringdist(txt1,txt2, method="jaccard", q=qgram))
}
if (method=="jw"){
return(jaro_winkler(txt1,txt2, p=jw_p))
}
if (method=="both"){
s1 <- jaccard_shingles(txt1,txt2, n=n_shingles)
s2 <- jaro_winkler(txt1,txt2, p=jw_p)
return((s1 + s2)/2)
}
}
muestra[, jacc_dist := clean_and_return_similarity(rsocial, NombreUltimaRevision, method = "jaccard", qgram = 3)]
clean_and_return_similarity <- function(txt1,txt2, method='jaccard', qgram=3, jw_p=0.1){
txt1 <- CleaningRE(txt1)
txt2 <- CleaningRE(txt2)
if (method=="jaccard"){
return(stringdist(txt1,txt2, method="jaccard", q=qgram))
}
if (method=="jw"){
return(jaro_winkler(txt1,txt2, p=jw_p))
}
if (method=="both"){
s1 <- jaccard_shingles(txt1,txt2, n=n_shingles)
s2 <- jaro_winkler(txt1,txt2, p=jw_p)
return((s1 + s2)/2)
}
}
muestra[, jacc_dist := clean_and_return_similarity(rsocial, NombreUltimaRevision, method = "jaccard", qgram = 3)]
ggplot(data=muestra, aes(x=jacc_dist))+geom_density()+ggtitle("Jaro Distance Distribution")
View(muestra)
clean_and_return_similarity <- function(txt1,txt2, method='jaccard', qgram=3, jw_p=0.1){
txt1 <- CleaningRE(txt1)
txt2 <- CleaningRE(txt2)
if (method=="jaccard"){
return(1-stringdist(txt1,txt2, method="jaccard", q=qgram))
}
if (method=="jw"){
return(jaro_winkler(txt1,txt2, p=jw_p))
}
if (method=="both"){
s1 <- jaccard_shingles(txt1,txt2, n=n_shingles)
s2 <- jaro_winkler(txt1,txt2, p=jw_p)
return((s1 + s2)/2)
}
}
muestra[, jacc_dist := clean_and_return_similarity(rsocial, NombreUltimaRevision, method = "jaccard", qgram = 3)]
ggplot(data=muestra, aes(x=jacc_dist))+geom_density()+ggtitle("Jaccard Distance Distribution")
ggplot(data=muestra, aes(x=jaro_dist))+geom_density()+ggtitle("Jaro Distance Distribution")
ggplot(data=muestra, aes(x=jacc_dist))+geom_density()+ggtitle("Jaccard Distance Distribution")
ggplot(data=muestra, aes(x=jaro_dist))+geom_density()+ggtitle("Jaro Distance Distribution")
ggplot(data=muestra, aes(x=jacc_dist))+geom_density()+ggtitle("Jaccard Distance Distribution")
ggplot(data=muestra, aes(x=log10(jacc_dist)))+geom_density()+ggtitle("Jaccard Distance Distribution")
library(lhs)
set.seed(17)
A <- matrix(runif(20), 10, 2)
B <- optimumLHS(10, 2)
par(mfrow=c(1,2))
plot(A)
plot(B)
source("~/Escritorio/DATA SCIENCE/Economia y Finanzas/dmeyf/src/ranger/510_ranger_Nacho.r", echo=TRUE)
install.packages("randomForest")
source("~/Escritorio/DATA SCIENCE/Economia y Finanzas/dmeyf/src/ranger/510_ranger_Nacho.r", echo=TRUE)
install.packages("ranger")
install.packages("ranger", dependencies=TRUE)
source("~/Escritorio/DATA SCIENCE/Economia y Finanzas/dmeyf/src/ranger/510_ranger_Nacho.r", echo=TRUE)
# #Genero la entrega para Kaggle
# entrega  <- as.data.table( list( "numero_de_cliente"= dapply[  , numero_de_cliente],
#                                  "Predicted"= as.numeric(prediccion$predictions[ ,"POS" ] > 0.025) ) ) #genero la salida
#
# #genero el archivo para Kaggle
# fwrite( entrega,
#         file="./kaggle/ranger_001.csv",
#         sep="," )
importancia <- as.data.table(modelo$variable.importance,keep.rownames = TRUE)
View(importancia)
modelo$importance.mode
varImp(modelo)
names(modelo)
names(modelo$importance.mode)
str(modelo)
modelo$variable.importance
#
prediccion  <- predict( modelo, dapply )
dapply  <- fread("./datasetsOri/paquete_premium_202011_ext-17092021.csv", stringsAsFactors= TRUE)
dapply[ , clase_ternaria := NULL ]  #Elimino esta columna que esta toda en NA
dapply  <- na.roughfix( dapply )
dapply  <- fread("./datasetsOri/paquete_premium_202011_ext-17092021.csv", stringsAsFactors= TRUE)
dapply[ , clase_ternaria := NULL ]  #Elimino esta columna que esta toda en NA
dapply  <- na.roughfix( dapply )
#cargo los datos donde aplico el modelo
dapply  <- fread("./datasetsOri/paquete_premium_202011_ext-17092021.csv", stringsAsFactors= TRUE)
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("ranger")
require("randomForest")  #solo se usa para imputar nulos
#Aqui se debe poner la carpeta de la computadora local
setwd("~/Escritorio/DATA SCIENCE/Economia y Finanzas/dmeyf")  #Establezco el Working Directory
#cargo los datos donde entreno
dtrain  <- fread("./datasets/paquete_premium_202009_ext-17092021.csv", stringsAsFactors= TRUE)
dtrain[ , clase_binaria := as.factor(ifelse( clase_ternaria=="BAJA+2", "POS", "NEG" )) ]
dtrain[ , clase_ternaria := NULL ]  #elimino la clase_ternaria, ya no la necesito
#imputo los nulos, ya que ranger no acepta nulos
#Leo Breiman, ¿por que le temias a los nulos?
dtrain  <- na.roughfix( dtrain )
#cargo los datos donde aplico el modelo
dapply  <- fread("./datasetsOri/paquete_premium_202011_ext-17092021.csv", stringsAsFactors= TRUE)
dapply[ , clase_ternaria := NULL ]  #Elimino esta columna que esta toda en NA
dapply  <- na.roughfix( dapply )
#genero el modelo de Random Forest con la libreria ranger
param  <- list( "num.trees"=      500,  #cantidad de arboles
"mtry"=             sqrt(ncol(dtrain)),  #cantidad de variables que evalua para hacer un split
"min.node.size"=    1,  #hoja mas chica
"max.depth"=        0   # 0 significa profundidad infinita
)
set.seed(102191) #Establezco la semilla aleatoria
modelo  <- ranger( formula= "clase_binaria ~ .",
data=  dtrain,
probability=   TRUE,  #para que devuelva las probabilidades
num.trees=     param$num.trees,
mtry=          param$mtry,
min.node.size= param$min.node.size,
max.depth=     param$max.depth
)
#
prediccion  <- predict( modelo, dapply )
dapply  <- fread("./datasets/paquete_premium_202011_ext-17092021.csv", stringsAsFactors= TRUE)
dapply[ , clase_ternaria := NULL ]  #Elimino esta columna que esta toda en NA
dapply  <- na.roughfix( dapply )
#
prediccion  <- predict( modelo, dapply )
modelo$importance.mode
lgb.importance( model= modelo )
lightgbm::lgb.importance(model=modelo)
class(modelo)
importance(modelo)
View(modelo)
source("~/Escritorio/DATA SCIENCE/Economia y Finanzas/dmeyf/src/ranger/510_ranger_Nacho.r", echo=TRUE)
require("ggplot2")
ggplot(stack(modelo$variable.impotance), aes(ind, values)) + geom_col() + coord_flip()
ggplot(stack(modelo$variable.importance), aes(ind, values)) + geom_col() + coord_flip()
modelo$variable.importance
a <- as.data.frame(modelo$variable.importance )
View(a)
a <- as.data.frame(modelo$variable.importance,col.names = c("Var","Value"))
View(a)
a <- as.data.frame(modelo$variable.importance,col.names = c("Var","Value"))
a <- as.data.frame(modelo$variable.importance, optional = TRUE)
View(a)
a <- as.data.frame(modelo$variable.importance, col.names= c("Var", "Val"), optional = TRUE)
View(a)
vals <- modelo$variable.importance
var <- names(modelo$variable.importance)
df <- as.data.frame(var,vals)
View(df)
df <- data.frame(var,vals)
View(df)
df <- data.frame(var,vals, row.names = NULL)
View(df)
head(df[order(df$vals),])
head(df[order(-df$vals),])
df <- df[order(-df$vals),]
ggplot(df, aes(var, vals)) + geom_col() + coord_flip()
View(df)
ggplot(df[order(-df$vals),], aes(var, vals)) + geom_col() + coord_flip()
